{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.67 MiB for an array with shape (31353,) and data type [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\lung_project\\Section2\\best_combination.ipynb 儲存格 1\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/lung_project/Section2/best_combination.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m model_names:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/lung_project/Section2/best_combination.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_dir, model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/lung_project/Section2/best_combination.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         m \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(model_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/lung_project/Section2/best_combination.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         models\u001b[39m.\u001b[39mappend(m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/lung_project/Section2/best_combination.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Create a list of all possible model combinations (excluding an empty set and the full set of models)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:344\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(array_wrapper, NDArrayWrapper):\n\u001b[0;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompat_mode \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack\u001b[39m.\u001b[39mappend(array_wrapper\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:189\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    187\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_mmap(unpickler)\n\u001b[0;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(unpickler)\n\u001b[0;32m    191\u001b[0m \u001b[39m# Manage array subclass case\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mhasattr\u001b[39m(array, \u001b[39m'\u001b[39m\u001b[39m__array_prepare__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubclass \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m    194\u001b[0m                           unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mmemmap)):\n\u001b[0;32m    195\u001b[0m     \u001b[39m# We need to reconstruct another subclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:134\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read_array\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[39m# of the read. In non-chunked case count < max_read_count, so\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39m# only one read is performed.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     max_read_count \u001b[39m=\u001b[39m BUFFER_SIZE \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mmin\u001b[39m(BUFFER_SIZE,\n\u001b[0;32m    132\u001b[0m                                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize)\n\u001b[1;32m--> 134\u001b[0m     array \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mnp\u001b[39m.\u001b[39;49mempty(count, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m    135\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, count, max_read_count):\n\u001b[0;32m    136\u001b[0m         read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.67 MiB for an array with shape (31353,) and data type [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Assuming you have a list of 15 trained random forest models called \"models\"\n",
    "model_dir = \"vn\"\n",
    "model_names = os.listdir(model_dir)\n",
    "model_names = [f for f in model_names if f.endswith(\".joblib\")]\n",
    "\n",
    "# Load 15 saved models into a list\n",
    "models = []\n",
    "\n",
    "for model in model_names:\n",
    "        model_path = os.path.join(model_dir, model)\n",
    "        m = joblib.load(model_path)\n",
    "        models.append(m)\n",
    "\n",
    "# Create a list of all possible model combinations (excluding an empty set and the full set of models)\n",
    "model_combinations = [comb for i in range(1, len(models)) for comb in combinations(models, i)]\n",
    "\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "testing_dir = \"data/cross_validation/folder1/test\"\n",
    "\n",
    "# load testing data\n",
    "npy_files = os.listdir(testing_dir)\n",
    "testing_npy_files = [f for f in npy_files if (f.endswith(\"nodule_features.npy\") or f.endswith(\"vessel_features.npy\"))]\n",
    "\n",
    "testing_npy_list = []\n",
    "for npy_file in testing_npy_files:\n",
    "    npy_path = os.path.join(testing_dir, npy_file)\n",
    "    npy_array = np.load(npy_path)\n",
    "    testing_npy_list.append(npy_array)\n",
    "\n",
    "testing_features = np.concatenate(testing_npy_list, axis=0)\n",
    "\n",
    "X_test = testing_features[:, :-1]\n",
    "y_test = testing_features[:, -1]\n",
    "\n",
    "# adjust label domain\n",
    "y_test -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "0.858961487743239\n",
      "[0, 1, 7]\n",
      "0.859037020485109\n",
      "[1, 2, 6]\n",
      "0.8597168151619391\n",
      "[1, 2, 14]\n",
      "0.8601951891937824\n",
      "Best model combination: [1, 2, 14]\n",
      "Best accuracy: 0.8601951891937824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mode\n",
    "\n",
    "# Initialize best accuracy and corresponding best combination of models\n",
    "best_accuracy = 0\n",
    "best_combination = []\n",
    "\n",
    "# Loop over all model combinations and calculate voting accuracy on your validation dataset\n",
    "for combination in model_combinations:\n",
    "\n",
    "    if len(combination) != 3:\n",
    "        continue\n",
    "\n",
    "    # Calculate predictions on your validation dataset using the current model combination\n",
    "    predictions = []\n",
    "    for model in combination:\n",
    "        prediction = model.predict(X_test)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Take the majority vote to determine final prediction\n",
    "    combined_prediction = np.round(np.mean(predictions, axis=0))\n",
    "\n",
    "    # Calculate the accuracy of the combined prediction\n",
    "    accuracy = accuracy_score(y_test, combined_prediction)\n",
    "\n",
    "    # Check if the current combination has better accuracy than the previous best combination\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_combination = combination\n",
    "        print([models.index(model) for model in best_combination])\n",
    "        print(best_accuracy)\n",
    "\n",
    "\n",
    "# Print the best combination of models and corresponding accuracy\n",
    "print(\"Best model combination:\", [models.index(model) for model in best_combination])\n",
    "print(\"Best accuracy:\", best_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
